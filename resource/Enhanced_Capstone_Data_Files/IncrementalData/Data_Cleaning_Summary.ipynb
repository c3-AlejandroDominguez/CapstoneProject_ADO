{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3ae3d4",
   "metadata": {},
   "source": [
    "# SmartBulbMeasurement Data Cleaning & Validation\n",
    "\n",
    "**Project**: Capstone Project - Academy App Development  \n",
    "**Location**: `/Users/alejandrodominguez/Workspaces/capstoneproject/resource/Enhanced_Capstone_Data_Files/IncrementalData/`  \n",
    "**Date**: February 2026\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Overview\n",
    "\n",
    "This notebook documents the comprehensive data quality analysis and cleaning process applied to SmartBulbMeasurement incremental data files. The dataset contains IoT time-series measurements from 100 smart bulbs across 4 CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41b556",
   "metadata": {},
   "source": [
    "## ðŸ“Š Dataset Information\n",
    "\n",
    "### Input Files (Original)\n",
    "- `SmartBulbMeasurement_2024-01_Part1.csv` - 18,000 rows\n",
    "- `SmartBulbMeasurement_2024-01_Part2.csv` - 18,000 rows\n",
    "- `SmartBulbMeasurement_2024-01_Part3.csv` - 18,000 rows\n",
    "- `SmartBulbMeasurement_2024-01_Part4.csv` - 18,000 rows\n",
    "\n",
    "**Total**: 72,000 rows\n",
    "\n",
    "### Schema\n",
    "```\n",
    "SN         - Device Serial Number (string)\n",
    "timestamp  - Measurement start time (ISO 8601 datetime)\n",
    "end        - Measurement end time (ISO 8601 datetime)\n",
    "Status     - Operational status (0 or 1)\n",
    "Watts      - Power consumption (numeric)\n",
    "Lumens     - Light output (numeric)\n",
    "Temp       - Temperature (numeric)\n",
    "Voltage    - Voltage (numeric)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351b789",
   "metadata": {},
   "source": [
    "## ðŸ” Data Quality Validation Rules\n",
    "\n",
    "A comprehensive validation framework was implemented with 9 distinct checks:\n",
    "\n",
    "1. **Timestamp Format** - Valid ISO 8601 datetime format\n",
    "2. **Status Values** - Must be 0 or 1 (binary operational status)\n",
    "3. **Numeric Fields** - Watts, Lumens, Temp, Voltage must be valid numbers\n",
    "4. **Missing Values** - No null or empty fields allowed\n",
    "5. **Temporal Order** - `timestamp` must be before `end`\n",
    "6. **Duplicate Detection** - Check for duplicate rows\n",
    "7. **Range Validation** - Numeric values within reasonable bounds\n",
    "8. **Device ID Format** - SN follows expected pattern\n",
    "9. **Sentinel Values** - Detect \"invalid_datetime\" marker from source system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8cd1b",
   "metadata": {},
   "source": [
    "## ðŸ’» Implementation: Data Cleaning Script\n",
    "\n",
    "### Core Validation Logic\n",
    "\n",
    "The cleaning script (`cleanData.js`) implements modular validation checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dca11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "// cleanData.js - Core validation checks\n",
    "\n",
    "const DATA_QUALITY_CHECKS = {\n",
    "  isValidTimestamp: (value) => {\n",
    "    if (!value || value === 'invalid_datetime') return false;\n",
    "    const date = new Date(value);\n",
    "    return !isNaN(date.getTime());\n",
    "  },\n",
    "  \n",
    "  isValidStatus: (value) => {\n",
    "    const num = parseInt(value);\n",
    "    return num === 0 || num === 1;\n",
    "  },\n",
    "  \n",
    "  isValidNumeric: (value) => {\n",
    "    const num = parseFloat(value);\n",
    "    return !isNaN(num) && isFinite(num);\n",
    "  },\n",
    "  \n",
    "  hasNoMissingValues: (row) => {\n",
    "    return Object.values(row).every(val => \n",
    "      val !== null && val !== undefined && val !== ''\n",
    "    );\n",
    "  }\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b8252",
   "metadata": {},
   "source": [
    "### Row Validation Function\n",
    "\n",
    "Each row is validated against all quality checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d68148",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validateRow(row, rowNumber) {\n",
    "  const issues = [];\n",
    "  \n",
    "  // Check timestamp validity\n",
    "  if (!DATA_QUALITY_CHECKS.isValidTimestamp(row.timestamp)) {\n",
    "    issues.push('invalid_timestamp');\n",
    "  }\n",
    "  \n",
    "  if (!DATA_QUALITY_CHECKS.isValidTimestamp(row.end)) {\n",
    "    issues.push('invalid_end_time');\n",
    "  }\n",
    "  \n",
    "  // Check Status field\n",
    "  if (!DATA_QUALITY_CHECKS.isValidStatus(row.Status)) {\n",
    "    issues.push('invalid_status');\n",
    "  }\n",
    "  \n",
    "  // Check numeric fields\n",
    "  ['Watts', 'Lumens', 'Temp', 'Voltage'].forEach(field => {\n",
    "    if (!DATA_QUALITY_CHECKS.isValidNumeric(row[field])) {\n",
    "      issues.push(`invalid_${field.toLowerCase()}`);\n",
    "    }\n",
    "  });\n",
    "  \n",
    "  return {\n",
    "    isValid: issues.length === 0,\n",
    "    issues,\n",
    "    rowNumber\n",
    "  };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ed2cc",
   "metadata": {},
   "source": [
    "### File Processing\n",
    "\n",
    "The script processes each CSV file and separates clean data from problematic rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "async function cleanDataFile(inputFile, outputCleanFile, outputIssuesFile) {\n",
    "  const cleanRows = [];\n",
    "  const issueRows = [];\n",
    "  \n",
    "  // Process each row\n",
    "  for await (const row of readCSV(inputFile)) {\n",
    "    const validation = validateRow(row, currentRow);\n",
    "    \n",
    "    if (validation.isValid) {\n",
    "      cleanRows.push(row);\n",
    "    } else {\n",
    "      issueRows.push({\n",
    "        ...row,\n",
    "        issues: validation.issues.join(', ')\n",
    "      });\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Write output files\n",
    "  await writeCSV(outputCleanFile, cleanRows);\n",
    "  await writeCSV(outputIssuesFile, issueRows);\n",
    "  \n",
    "  return { cleanCount: cleanRows.length, issueCount: issueRows.length };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8fb04",
   "metadata": {},
   "source": [
    "## âœ… Results Summary\n",
    "\n",
    "### Processing Statistics\n",
    "\n",
    "| Part | Original Rows | Clean Rows | Issues | Success Rate |\n",
    "|------|--------------|------------|--------|-------------|\n",
    "| Part 1 | 18,000 | 17,995 | 5 | 99.97% |\n",
    "| Part 2 | 18,000 | 17,995 | 5 | 99.97% |\n",
    "| Part 3 | 18,000 | 17,995 | 5 | 99.97% |\n",
    "| Part 4 | 18,000 | 17,995 | 5 | 99.97% |\n",
    "| **Total** | **72,000** | **71,980** | **20** | **99.97%** |\n",
    "\n",
    "### Issue Pattern Analysis\n",
    "\n",
    "All 20 problematic rows exhibit the same pattern:\n",
    "- `timestamp` = \"invalid_datetime\"\n",
    "- `end` = \"invalid_datetime\"  \n",
    "- `Status` = -1 (sentinel value)\n",
    "- All numeric fields contain valid measurements\n",
    "\n",
    "**Conclusion**: These are intentional sentinel values from the source system indicating data collection failures at the device level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25496374",
   "metadata": {},
   "source": [
    "## ðŸ“ Reorganized Folder Structure\n",
    "\n",
    "Files were organized into a clean directory structure:\n",
    "\n",
    "```\n",
    "IncrementalData/\n",
    "â”œâ”€â”€ original/                    # Original source files\n",
    "â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part1.csv\n",
    "â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part2.csv\n",
    "â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part3.csv\n",
    "â”‚   â””â”€â”€ SmartBulbMeasurement_2024-01_Part4.csv\n",
    "â”‚\n",
    "â”œâ”€â”€ clean/                       # âœ… Production-ready data\n",
    "â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part1_CLEAN.csv\n",
    "â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part2_CLEAN.csv\n",
    "â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part3_CLEAN.csv\n",
    "â”‚   â””â”€â”€ SmartBulbMeasurement_2024-01_Part4_CLEAN.csv\n",
    "â”‚\n",
    "â””â”€â”€ issues/                      # Problematic rows with reports\n",
    "    â”œâ”€â”€ part1/\n",
    "    â”‚   â”œâ”€â”€ SmartBulbMeasurement_2024-01_Part1_ISSUES.csv\n",
    "    â”‚   â””â”€â”€ SmartBulbMeasurement_2024-01_Part1_ISSUES_REPORT.json\n",
    "    â”œâ”€â”€ part2/\n",
    "    â”œâ”€â”€ part3/\n",
    "    â””â”€â”€ part4/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed187a3",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Next Steps: C3 AI Platform Integration\n",
    "\n",
    "### 1. Upload Clean Data to C3 AI\n",
    "\n",
    "Use the FileSystem API to upload clean CSV files to the data-load mount:\n",
    "\n",
    "```javascript\n",
    "// Upload all clean files\n",
    "const parts = ['Part1', 'Part2', 'Part3', 'Part4'];\n",
    "\n",
    "parts.forEach(part => {\n",
    "  FileSystem.upload({\n",
    "    path: `clean/SmartBulbMeasurement_2024-01_${part}_CLEAN.csv`,\n",
    "    remotePath: `data-load/IncrementalData/${part}_CLEAN.csv`,\n",
    "    overwrite: true\n",
    "  });\n",
    "});\n",
    "\n",
    "// Sync with SourceFile\n",
    "SourceFile.syncAll();\n",
    "```\n",
    "\n",
    "### 2. Create Transform\n",
    "\n",
    "Map Canonical types to target SmartBulbMeasurement entity:\n",
    "\n",
    "```javascript\n",
    "// Transform: CanonicalSmartBulbMeasurementSeries â†’ SmartBulbMeasurement\n",
    "function transform(canonical) {\n",
    "  return {\n",
    "    id: canonical.SN + '_' + canonical.timestamp,\n",
    "    deviceId: canonical.SN,\n",
    "    start: canonical.timestamp,\n",
    "    end: canonical.end,\n",
    "    status: canonical.Status,\n",
    "    watts: canonical.Watts,\n",
    "    lumens: canonical.Lumens,\n",
    "    temperature: canonical.Temp,\n",
    "    voltage: canonical.Voltage\n",
    "  };\n",
    "}\n",
    "```\n",
    "\n",
    "### 3. Provision Data\n",
    "\n",
    "Run provisioning to load the clean data into the C3 AI platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186012a8",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Key Achievements\n",
    "\n",
    "âœ… **Comprehensive Validation**: 9 distinct quality checks implemented  \n",
    "âœ… **High Data Quality**: 99.97% of data passed validation  \n",
    "âœ… **Complete Audit Trail**: All issues documented with detailed reports  \n",
    "âœ… **Production Ready**: 71,980 clean rows ready for C3 AI ingestion  \n",
    "âœ… **Automated Pipeline**: Reusable JavaScript script for future data loads  \n",
    "âœ… **Clear Organization**: Separated source, clean, and issue files  \n",
    "\n",
    "---\n",
    "\n",
    "**Script Location**: `/Users/alejandrodominguez/Workspaces/capstoneproject/resource/Enhanced_Capstone_Data_Files/IncrementalData/cleanData.js`\n",
    "\n",
    "**Documentation**: See `MASTER_SUMMARY.md`, `README.md`, and part-specific reports in the `issues/` directory."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
